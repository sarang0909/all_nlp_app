{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Please refer https://github.com/sarang0909/news_api   for getting news data.\n",
                "## Also I've used my open sourced library https://github.com/sarang0909/nlp_text_cleaner  for text cleaning "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collecting nlp-text-cleaner\n",
                        "  Using cached nlp_text_cleaner-1.0.11-py3-none-any.whl (5.3 kB)\n",
                        "Collecting langdetect\n",
                        "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
                        "Requirement already satisfied: nltk in c:\\users\\metes\\anaconda3\\envs\\semantic_search_api\\lib\\site-packages (from nlp-text-cleaner) (3.7)\n",
                        "Collecting autocorrect\n",
                        "  Using cached autocorrect-2.6.1-py3-none-any.whl\n",
                        "Requirement already satisfied: regex in c:\\users\\metes\\anaconda3\\envs\\semantic_search_api\\lib\\site-packages (from nlp-text-cleaner) (2022.10.31)\n",
                        "Requirement already satisfied: six in c:\\users\\metes\\anaconda3\\envs\\semantic_search_api\\lib\\site-packages (from langdetect->nlp-text-cleaner) (1.16.0)\n",
                        "Requirement already satisfied: click in c:\\users\\metes\\appdata\\roaming\\python\\python38\\site-packages (from nltk->nlp-text-cleaner) (8.0.4)\n",
                        "Requirement already satisfied: joblib in c:\\users\\metes\\anaconda3\\envs\\semantic_search_api\\lib\\site-packages (from nltk->nlp-text-cleaner) (1.2.0)\n",
                        "Requirement already satisfied: tqdm in c:\\users\\metes\\anaconda3\\envs\\semantic_search_api\\lib\\site-packages (from nltk->nlp-text-cleaner) (4.64.1)\n",
                        "Requirement already satisfied: colorama in c:\\users\\metes\\anaconda3\\envs\\semantic_search_api\\lib\\site-packages (from click->nltk->nlp-text-cleaner) (0.4.6)\n",
                        "Installing collected packages: langdetect, autocorrect, nlp-text-cleaner\n",
                        "Successfully installed autocorrect-2.6.1 langdetect-1.0.9 nlp-text-cleaner-1.0.11\n"
                    ]
                }
            ],
            "source": [
                "!pip install --upgrade nlp-text-cleaner"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package stopwords to\n",
                        "[nltk_data]     C:\\Users\\metes\\AppData\\Roaming\\nltk_data...\n",
                        "[nltk_data]   Package stopwords is already up-to-date!\n",
                        "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
                        "[nltk_data]     C:\\Users\\metes\\AppData\\Roaming\\nltk_data...\n",
                        "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
                        "[nltk_data]       date!\n",
                        "[nltk_data] Downloading package punkt to\n",
                        "[nltk_data]     C:\\Users\\metes\\AppData\\Roaming\\nltk_data...\n",
                        "[nltk_data]   Package punkt is already up-to-date!\n",
                        "[nltk_data] Downloading package wordnet to\n",
                        "[nltk_data]     C:\\Users\\metes\\AppData\\Roaming\\nltk_data...\n",
                        "[nltk_data]   Package wordnet is already up-to-date!\n",
                        "[nltk_data] Downloading package omw-1.4 to\n",
                        "[nltk_data]     C:\\Users\\metes\\AppData\\Roaming\\nltk_data...\n",
                        "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "from nlp_text_cleaner import nlp_text_cleaner as cleaner"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 80 entries, 0 to 79\n",
                        "Data columns (total 10 columns):\n",
                        " #   Column        Non-Null Count  Dtype \n",
                        "---  ------        --------------  ----- \n",
                        " 0   Unnamed: 0    80 non-null     int64 \n",
                        " 1   source        80 non-null     object\n",
                        " 2   author        6 non-null      object\n",
                        " 3   title         80 non-null     object\n",
                        " 4   description   80 non-null     object\n",
                        " 5   url           80 non-null     object\n",
                        " 6   urlToImage    80 non-null     object\n",
                        " 7   publishedAt   80 non-null     object\n",
                        " 8   content       80 non-null     object\n",
                        " 9   article_text  79 non-null     string\n",
                        "dtypes: int64(1), object(8), string(1)\n",
                        "memory usage: 6.4+ KB\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "Int64Index: 79 entries, 0 to 79\n",
                        "Data columns (total 10 columns):\n",
                        " #   Column        Non-Null Count  Dtype \n",
                        "---  ------        --------------  ----- \n",
                        " 0   Unnamed: 0    79 non-null     int64 \n",
                        " 1   source        79 non-null     object\n",
                        " 2   author        5 non-null      object\n",
                        " 3   title         79 non-null     object\n",
                        " 4   description   79 non-null     object\n",
                        " 5   url           79 non-null     object\n",
                        " 6   urlToImage    79 non-null     object\n",
                        " 7   publishedAt   79 non-null     object\n",
                        " 8   content       79 non-null     object\n",
                        " 9   article_text  79 non-null     string\n",
                        "dtypes: int64(1), object(8), string(1)\n",
                        "memory usage: 6.8+ KB\n"
                    ]
                }
            ],
            "source": [
                "raw_data = pd.read_csv('../../data/raw_data.csv',dtype={'article_text':'string'})\n",
                "raw_data.info()\n",
                "raw_data = raw_data.dropna(subset=['article_text'])\n",
                "raw_data.info()\n",
                "paragraph_clean_data = pd.DataFrame()\n",
                "paragraph_clean_data['paragraph'] = raw_data[\"article_text\"].apply(cleaner.clean_paragraph)\n",
                "paragraph_clean_data['url'] = raw_data['url']\n",
                "paragraph_clean_data.to_csv('../../data/paragraph_clean_data.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 ('semantic_search_api')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "55df16ff64e9c78b3a7965dd2238b97852cf2f250eb658b4807682d11d53b305"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
